{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T07:24:36.300122Z",
     "start_time": "2019-06-11T07:24:34.391962Z"
    }
   },
   "source": [
    "# Voedselprijzen in de derde wereld\n",
    "\n",
    "Robert-Jan Korteschiel (10399143)  \n",
    "Robert Houten  \n",
    "Sander Kohnstamm (10715363)  \n",
    "Joost de Wildt (12173002)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T07:54:53.108672Z",
     "start_time": "2019-06-11T07:54:53.097408Z"
    }
   },
   "source": [
    "## Vooronderzoek\n",
    "\n",
    "Dit is een dataset die wekelijks wordt geupdated over voedselprijzen. De auteur is het World Food Programme, een humanitaire organisatie die steeft naar het ideaal van \"zero hunger\". Daar baseren ze al hun werk al op data en hebben ook al goede dataviz draaien. Interessant is dat ze hier combineren met veel GIS informatie zoals administratieve grenzen, wegennetwerken en klimaatdata. \n",
    "\n",
    "<div style=\"display: flex; width: 100%; justify-content: space-around;\">\n",
    "    <div style=\"width: 45%\">\n",
    "        <img src=\"food_viz.png\" style=\"display: block; width: 100%; height: auto;\" alt=\"GIS visualisation\">\n",
    "    </div>\n",
    "    <div style=\"width: 45%\">\n",
    "        <img src=\"patterns.jpg\" style=\"display: block; width: 100%; height: auto;\" alt=\"Line visualisation\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "Er is dus al veel werk gedaan op de data, maar er mist ook veel informatie. Opvallend is dat economische en politieke gegevens missen in de analyse. Daarnaast bekijken ze de derde wereld echt per land en zien kijken ze bijna niet naar hoe deze problematiek grensoverstijgend is (of is dat wel zo?). Bovendien is het alles behalve een verhaal, dit is echt een visualisatie. Het is interessant of we delen kunnen namaken en tot een verhaal kunnen omvormen. \n",
    "\n",
    "[bron] https://data.humdata.org/dataset/wfp-food-prices  \n",
    "[algemene omschriving] https://docs.wfp.org/api/documents/WFP-0000040024/download/   \n",
    "[dierpere omschrijving] http://mvam.org/2018/11/20/getting-up-to-speed-wfp-food-data-on-hdx/  \n",
    "[snelle verkenning] https://dataviz.vam.wfp.org   \n",
    "[UN exchange rates] https://treasury.un.org/operationalrates/OperationalRates.php  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invalshoeken\n",
    "\n",
    "1. Welke van de volgende gebeurtenissen heeft de grootste invloed op globale voedselprijzen?\n",
    "    - Temperatuur\n",
    "    - Brandstofprijs\n",
    "    - Dagloon  \n",
    "\n",
    "\n",
    "2. Vallen gebeurtenissen te herleiden uit voedselprijzen?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food\n",
    "\n",
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T13:30:09.076014Z",
     "start_time": "2019-06-19T13:30:09.069855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from sklearn import preprocessing\n",
    "from operator import itemgetter, attrgetter\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from functools import partial\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_seq_items = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inladen\n",
    "\n",
    "en laat de head() zien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:10.926879Z",
     "start_time": "2019-06-19T09:58:08.512918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adm0_id</th>\n",
       "      <th>adm0_name</th>\n",
       "      <th>adm1_id</th>\n",
       "      <th>adm1_name</th>\n",
       "      <th>mkt_id</th>\n",
       "      <th>mkt_name</th>\n",
       "      <th>cm_id</th>\n",
       "      <th>cm_name</th>\n",
       "      <th>cur_id</th>\n",
       "      <th>cur_name</th>\n",
       "      <th>pt_id</th>\n",
       "      <th>pt_name</th>\n",
       "      <th>um_id</th>\n",
       "      <th>um_name</th>\n",
       "      <th>mp_month</th>\n",
       "      <th>mp_year</th>\n",
       "      <th>mp_price</th>\n",
       "      <th>mp_commoditysource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>272</td>\n",
       "      <td>Badakhshan</td>\n",
       "      <td>266</td>\n",
       "      <td>Fayzabad</td>\n",
       "      <td>55</td>\n",
       "      <td>Bread - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AFN</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>272</td>\n",
       "      <td>Badakhshan</td>\n",
       "      <td>266</td>\n",
       "      <td>Fayzabad</td>\n",
       "      <td>55</td>\n",
       "      <td>Bread - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AFN</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>272</td>\n",
       "      <td>Badakhshan</td>\n",
       "      <td>266</td>\n",
       "      <td>Fayzabad</td>\n",
       "      <td>55</td>\n",
       "      <td>Bread - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AFN</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>272</td>\n",
       "      <td>Badakhshan</td>\n",
       "      <td>266</td>\n",
       "      <td>Fayzabad</td>\n",
       "      <td>55</td>\n",
       "      <td>Bread - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AFN</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>272</td>\n",
       "      <td>Badakhshan</td>\n",
       "      <td>266</td>\n",
       "      <td>Fayzabad</td>\n",
       "      <td>55</td>\n",
       "      <td>Bread - Retail</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AFN</td>\n",
       "      <td>15</td>\n",
       "      <td>Retail</td>\n",
       "      <td>5</td>\n",
       "      <td>KG</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adm0_id    adm0_name  adm1_id   adm1_name  mkt_id  mkt_name  cm_id  \\\n",
       "0      1.0  Afghanistan      272  Badakhshan     266  Fayzabad     55   \n",
       "1      1.0  Afghanistan      272  Badakhshan     266  Fayzabad     55   \n",
       "2      1.0  Afghanistan      272  Badakhshan     266  Fayzabad     55   \n",
       "3      1.0  Afghanistan      272  Badakhshan     266  Fayzabad     55   \n",
       "4      1.0  Afghanistan      272  Badakhshan     266  Fayzabad     55   \n",
       "\n",
       "          cm_name  cur_id cur_name  pt_id pt_name  um_id um_name  mp_month  \\\n",
       "0  Bread - Retail     0.0      AFN     15  Retail      5      KG         1   \n",
       "1  Bread - Retail     0.0      AFN     15  Retail      5      KG         2   \n",
       "2  Bread - Retail     0.0      AFN     15  Retail      5      KG         3   \n",
       "3  Bread - Retail     0.0      AFN     15  Retail      5      KG         4   \n",
       "4  Bread - Retail     0.0      AFN     15  Retail      5      KG         5   \n",
       "\n",
       "   mp_year  mp_price  mp_commoditysource  \n",
       "0     2014      50.0                 NaN  \n",
       "1     2014      50.0                 NaN  \n",
       "2     2014      50.0                 NaN  \n",
       "3     2014      50.0                 NaN  \n",
       "4     2014      50.0                 NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "food_df = pd.read_csv(\"./food_data/food.csv\", low_memory=False)\n",
    "display(food_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T13:34:03.139433Z",
     "start_time": "2019-06-15T13:34:03.135172Z"
    }
   },
   "source": [
    "### Groeperen\n",
    "\n",
    "De vergelijkbaarheid per commodity per land echt heel laag, maar hele korte stukken data overlappen echt. Het WFP meet blijkbaar alleen als ze geinteresseerd zijn in iets, om de een of andere reden. Vervolgens redeneren we dat we al het voedsel samentrekken tot een enkele trend, dat moet de vergelijkbaarheid al aardig hoger maken. Voor onze onderzoeksvraag is het immers alleen interessant dat we veranderingen in voedselprijzen afzetten tegen brandstof, lonen en klimaat. Misschien dat we daarna gewoon een land kiezen met het meeste data, los van de vergelijkbaarheid, voor de andere onderzoeksvraag.\n",
    "\n",
    "Groepeert alle commodities op basis het het eerste woord in hun definitie. \n",
    "\n",
    "**LET OP! Hier zit een grote assumptie. Een jaar kan een waarde krijgen op een enkele meting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:13.772088Z",
     "start_time": "2019-06-19T09:58:12.582217Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# groepeer de commodities met hun eerst woord\n",
    "pat = '^([\\w\\-]+)'\n",
    "selection = food_df[\"cm_name\"].str.extract(pat, expand=False)\n",
    "\n",
    "# run the foodtype string reduction\n",
    "food_df[\"cm_name_selected\"] = selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse time\n",
    "\n",
    "Voeg een kolom toe met de date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:16.318172Z",
     "start_time": "2019-06-19T09:58:15.295526Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dates = food_df[[\"mp_year\", \"mp_month\"]].assign(day=1).rename(columns={\"mp_year\": \"year\", \"mp_month\": \"month\"})\n",
    "food_df[\"dt\"] = pd.to_datetime(dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Transformatie\n",
    "\n",
    "### Normalisatie\n",
    "\n",
    "Normalisatie functie voor verschillende groepen in de data. Ik vermoed dat je het beste binnen een land op commodity kan normaliseren. Doe je het op een andere plek dan worden minder waardevolle commodities binnen groepen minder belangrijk. Het is aannemelijk dat graan wholesale flink goedkoper is dan graan retail. Als je die in absolute nummers optelt dan domineert het verschil in de retailprijs.\n",
    "\n",
    "Je zou overigens nog een argument kunnen maken dat je eigenlijk op provincie of zelfs stadsniveau moet gaan normaliseren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:27.183049Z",
     "start_time": "2019-06-19T09:58:17.882391Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_group(key, group_df):\n",
    "    # bootstrap a new normalizer   \n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    # reshape the series to array so that the normalizer accepts it\n",
    "    to_normalize = group_df[key].values.reshape(-1, 1)\n",
    "    \n",
    "    # do the actual normalisation     \n",
    "    x_scaled = min_max_scaler.fit_transform(to_normalize)\n",
    "    \n",
    "    # undo some weird numpy nesting of arrays    \n",
    "    x_scaled = np.concatenate(x_scaled).ravel()\n",
    "    \n",
    "    # concatenate it to the group_df    \n",
    "    group_df[f\"{key}_norm\"] = x_scaled\n",
    "    \n",
    "    # trow the group out     \n",
    "    return group_df\n",
    "    \n",
    "food_norm_df = food_df.groupby(by=[\"adm0_name\", \"cm_name\"]).apply(partial(normalize_group, \"mp_price\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Selecteren \n",
    "\n",
    "Verkenning en functies om te selecteren.\n",
    "\n",
    "Spoiler: De groep \"Rice\" heeft de meeste datapunten en 2016 is het jaar met de minste NaN's.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verkenning: Barchart\n",
    "\n",
    "Maar welke goederen zijn daadwerkelijk interessant? Totaal aantal records of jaren per land met data.\n",
    "\n",
    "**Dee laatste kwaliteit metriek gebruik ik in de rest van de selecties, met toevoeging van brandstof en wage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:29.237180Z",
     "start_time": "2019-06-19T09:58:28.806168Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d39fe1faf24b8b8fd0a71f7feb89e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='barchart_type', options=('total records', 'per year, per country')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# run a groupby for use later on\n",
    "grouped_commodity_df = food_norm_df.groupby(by=[\"adm0_name\", selection, \"mp_year\"])\n",
    "\n",
    "def barchart_records():\n",
    "    # calculate\n",
    "    quality_count = grouped_commodity_df[\"mp_price\"].count().reset_index().groupby(by=\"cm_name\")[\"mp_price\"].sum().sort_values()\n",
    "\n",
    "    # truncate the long barchart\n",
    "    quality_count_trunc = quality_count[-20:]\n",
    "\n",
    "    # visualize\n",
    "    barchart_trace = go.Bar(y=quality_count_trunc.index, x=quality_count_trunc.values, orientation = 'h')\n",
    "\n",
    "    layout = go.Layout(\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height= 200 + 20 * len(quality_count_trunc.index),\n",
    "        yaxis=dict(\n",
    "            showticklabels=True,\n",
    "            automargin=True\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=[barchart_trace], layout=layout)\n",
    "    print(f\"Total sum of records: {quality_count.sum()} \" )\n",
    "    iplot(fig)\n",
    "\n",
    "def barchart_years():\n",
    "    quality_years = grouped_commodity_df[\"mp_price_norm\"].mean().reset_index().groupby(by=[\"cm_name\"])[\"mp_price_norm\"].count().sort_values()\n",
    "    quality_years_trunc = quality_years[-20:]\n",
    "\n",
    "    barchart_trace = go.Bar(y=quality_years_trunc.index, x=quality_years_trunc.values, orientation = 'h')\n",
    "\n",
    "    layout = go.Layout(\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height= 200 + 20 * len(quality_years_trunc.index),\n",
    "        yaxis=dict(\n",
    "            showticklabels=True,\n",
    "            automargin=True\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=[barchart_trace], layout=layout)\n",
    "    print(f\"Total sum of year with data: {quality_years.sum()} \" )\n",
    "    iplot(fig)\n",
    "\n",
    "def barswitcher(barchart_type):\n",
    "    if barchart_type == \"total records\":\n",
    "        barchart_records()\n",
    "    if barchart_type == \"per year, per country\":\n",
    "        barchart_years()\n",
    "\n",
    "interact(barswitcher, barchart_type=[\"total records\", \"per year, per country\"])\n",
    "\n",
    "# Doe de eerste tien en concatenate wage (fuel zit al in deze lijst)\n",
    "selectie = [*grouped_commodity_df[\"mp_price_norm\"].mean().reset_index().groupby(by=[\"cm_name\"])[\"mp_price_norm\"].count().sort_values(ascending=False)[:10].index, \"Wage\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verkenning: Heatmap\n",
    "\n",
    "Even een beetje verkenning om wat beter zicht op de data te krijgen. In deze visualisatie kun je goed zien waar het gewicht in de data zit. Hier zie je goed hoe een goed per land zit. De barcharts geven slecht totalen aan, hier zie je de daarwerkelijke verdeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:31.492896Z",
     "start_time": "2019-06-19T09:58:30.887881Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3163c122a9b24e2f9987156a338fd413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='yaxis', options=('commodity', 'country'), value='commodity'), Drop…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def heatmap_quality(yaxis, zaxis, commodity, country):\n",
    "    print(\"TOTAL MEASUREMENTS: \", grouped_commodity_df[\"mp_price_norm\"].count().sum())\n",
    "    if zaxis == \"count\":\n",
    "        quality = grouped_commodity_df[\"mp_price_norm\"].count()\n",
    "        zmax = 100\n",
    "        zmin = 0\n",
    "        colorscale = \"Viridis\"\n",
    "    elif zaxis == \"price_norm\":\n",
    "        quality = grouped_commodity_df[\"mp_price_norm\"].mean()\n",
    "        zmax = 1\n",
    "        zmin = -1\n",
    "        colorscale = \"Portland\"\n",
    "    else:\n",
    "        quality = grouped_commodity_df[\"mp_price_norm\"].mean().groupby(level=[0,1]).diff()\n",
    "        zmax = 0.4\n",
    "        zmin = -0.4\n",
    "        colorscale = \"Portland\"\n",
    "    \n",
    "    if yaxis == \"commodity\":\n",
    "        quality = quality.xs(commodity, level=1).unstack(level=1)\n",
    "        quality = quality.reindex(sorted(quality.columns), axis=1)\n",
    "    \n",
    "    elif yaxis == \"country\":\n",
    "        quality = quality.xs(country, level=0).unstack(level=1)\n",
    "        quality = quality.reindex(sorted(quality.columns), axis=1)\n",
    "\n",
    "    heatmap_trace = go.Heatmap(z = quality.values, x=quality.columns, y=quality.index, colorscale= colorscale, zmin=zmin, zmax=zmax)\n",
    "    \n",
    "    layout = go.Layout(\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height= 200 + 20 * len(quality.index),\n",
    "        xaxis={\"range\": [1990, 2019]},\n",
    "        yaxis=dict(\n",
    "            showticklabels=True,\n",
    "            automargin=True\n",
    "        ),\n",
    "        title=commodity if yaxis == \"commodity\" else country\n",
    "    )\n",
    "\n",
    "    \n",
    "    fig = go.Figure(data=[heatmap_trace], layout=layout)\n",
    "    print(\"EITHER THE COMMODITY OR COUNTRY VARIABLE IS RENDERED, NOT COMBINATIONS\")\n",
    "    iplot(fig)\n",
    "\n",
    "    \n",
    "nestedInteract = interact(heatmap_quality, yaxis=[\"commodity\", \"country\"], zaxis=[\"count\", \"price_norm\", \"price_norm_diff\"], commodity=[*selectie], country=[*food_norm_df[\"adm0_name\"].unique()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T15:09:03.651124Z",
     "start_time": "2019-06-17T15:09:03.646090Z"
    }
   },
   "source": [
    "#### Verkenning: Outliers scatterplots\n",
    "\n",
    "Ik gooi heel doodleuk .mean().diff() op de dataset. Klaar, paar transformaties ertussen en huppathee. Maar de mean is geen robuuste metriek van centraliteit. Even iets meer zicht krijgen op de lijnen die ik aan het reduceren ben tot een gemiddelde.\n",
    "\n",
    "Eerst even wat prep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T13:46:13.130254Z",
     "start_time": "2019-06-19T13:46:11.931033Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f98b9619f54f9d83211fe8282e923d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='norm', options=(True, False), value=True), Dropdown(description='c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.scatter_commodity_country(norm, country, commodity)>"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scatter_commodity_country(norm, country, commodity):\n",
    "    price_type = \"mp_price_norm\" if norm else \"mp_price\"\n",
    "\n",
    "    # select a country\n",
    "    if country == \"all\":\n",
    "        country_food_points = food_norm_df\n",
    "    else:\n",
    "        country_food_points = food_norm_df[food_norm_df[\"adm0_name\"] ==\n",
    "                                           country]\n",
    "\n",
    "    if commodity == \"all\":\n",
    "        pass\n",
    "    else:\n",
    "        country_food_points = country_food_points[\n",
    "            country_food_points[\"cm_name_selected\"] == commodity]\n",
    "\n",
    "    # make a scatter\n",
    "    scatter_trace = go.Scattergl(x=country_food_points[\"dt\"],\n",
    "                                 y=country_food_points[price_type],\n",
    "                                 mode='markers',\n",
    "                                 name=\"Meetpunten\",\n",
    "                                 marker=dict(color=\"#2077b4\",\n",
    "                                             size=2,\n",
    "                                             line=dict(width=0)))\n",
    "\n",
    "    # make a mean\n",
    "    county_food_mean = country_food_points.groupby(\n",
    "        by=[country_food_points.dt.dt.year])[price_type].mean()\n",
    "    line_trace = go.Scatter(x=county_food_mean.index,\n",
    "                            y=county_food_mean.values,\n",
    "                            name=\"Mean\")\n",
    "\n",
    "    # make a median\n",
    "    county_food_median = country_food_points.groupby(\n",
    "        by=[country_food_points.dt.dt.year])[price_type].median()\n",
    "    median_trace = go.Scatter(x=county_food_median.index,\n",
    "                              y=county_food_median.values,\n",
    "                              name=\"Mediaan\")\n",
    "\n",
    "    print(\"Unique commodities: \",\n",
    "          list(country_food_points[\"cm_name\"].unique()))\n",
    "\n",
    "    fig_scatter = go.Figure(data=[scatter_trace, median_trace, line_trace])\n",
    "    fig_scatter['layout'].update(title=f\"{country}: {commodity}\")\n",
    "    iplot(fig_scatter)\n",
    "\n",
    "    # Histogram construction         \n",
    "    histo_years = country_food_points[\"mp_year\"].unique()\n",
    "    fig_histo = tools.make_subplots(rows=math.ceil(len(histo_years) / 3), cols=3, print_grid=False)\n",
    "    \n",
    "    for i in range(len(histo_years)):\n",
    "        histo_data_year = country_food_points[(country_food_points[\"mp_year\"] == histo_years[i])]\n",
    "        histo_trace = go.Histogram(x=histo_data_year[\"mp_price_norm\"],\n",
    "                                   xbins=dict(\n",
    "                                       start=0,\n",
    "                                       end=1,\n",
    "                                       size=0.05,\n",
    "                                   ),\n",
    "                                   name=f\"{histo_years[i]}\"\n",
    "                                    )\n",
    "        \n",
    "        fig_histo.append_trace(histo_trace,  math.ceil((i + 1) / 3 ), i % 3 + 1)\n",
    "    \n",
    "    iplot(fig_histo)\n",
    "\n",
    "    # add some descriptives\n",
    "#     descriptives = country_food_points.groupby(by=[\"mp_year\"])[price_type].describe()\n",
    "#     descriptives = descriptives.append(country_food_points[price_type].describe().rename(\"Total\"))\n",
    "#     descriptives[\"coefficient of variation\"] = descriptives[\"std\"] / descriptives[\"mean\"]\n",
    "#     display(descriptives)\n",
    "\n",
    "interact(scatter_commodity_country,\n",
    "         norm=[True, False],\n",
    "         country=[*food_norm_df[\"adm0_name\"].unique(), \"all\"],\n",
    "         commodity=[*selectie, \"all\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verkenning: Graag alle patronen tegelijkertijd\n",
    "\n",
    "**WIP!! NIET AF!**\n",
    "\n",
    "Wat doen een mean over alle landen? Die we uiteindelijk nodig hebben om onze hypotheses te toetsen. Welke landen worden grof fout gerepresenteerd in de lijn? Grid met lijngrafieken met land en gemiddelde van alle landen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:36.572337Z",
     "start_time": "2019-06-19T09:58:36.548431Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'food_selected_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-270-ff018378f42f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0miplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounty_mean_trace\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0minteract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_commodity_country\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfood_selected_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"adm0_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommodity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselectie\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'food_selected_df' is not defined"
     ]
    }
   ],
   "source": [
    "def scatter_commodity_country(country, commodity):\n",
    "    # construct global mean WRONG!!!!!!!\n",
    "#     global_mean = food_selected_df[(food_selected_df[\"adm0_name\"] == country)][\"mp_price\"].groupby(by=[food_selected_df.dt.dt.year]).mean()\n",
    "#     display(global_mean)\n",
    "    \n",
    "    # select a country\n",
    "    country_food_points = food_selected_df[(food_selected_df[\"adm0_name\"] == country) & (food_selected_df[\"cm_name\"] == commodity)]\n",
    "    \n",
    "    # make a mean\n",
    "    county_food_mean = country_food_points.groupby(by=[country_food_points.dt.dt.year])[\"mp_price\"].mean()\n",
    "    county_mean_trace = go.Scatter(\n",
    "        x = county_food_mean.index,\n",
    "        y = county_food_mean.values,\n",
    "        name = \"Mean\"\n",
    "    )\n",
    "    \n",
    "    # global mean    \n",
    "    \n",
    "    iplot([county_mean_trace])\n",
    "\n",
    "interact(scatter_commodity_country, country=food_selected_df[\"adm0_name\"].unique(), commodity=selectie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T15:07:41.694738Z",
     "start_time": "2019-06-17T15:07:41.690078Z"
    }
   },
   "source": [
    "### Reduceren\n",
    "\n",
    "Het gemiddelde berekenen en het verschil per jaar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:36.584128Z",
     "start_time": "2019-06-19T09:58:13.647Z"
    }
   },
   "outputs": [],
   "source": [
    "# bereken het gemiddelde per jaar en vergelijk dat met het vorige jaar\n",
    "grouped_commodity_mean_df = grouped_commodity_df[\"mp_price_norm\"].mean()\n",
    "\n",
    "# unstack zodat het verschil per jaar berekend kan worden\n",
    "grouped_commodity_diff_df = grouped_commodity_mean_df.unstack(level=2).diff(axis=1)\n",
    "grouped_commodity_diff_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility\n",
    "\n",
    "Even voor het gemak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:36.590500Z",
     "start_time": "2019-06-19T09:58:14.239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utility om selecteren makkelijker te maken\n",
    "def select_commodity(commodity, year):\n",
    "    return grouped_commodity_diff_df.xs(commodity, level=1, drop_level=True)[year]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisatie: Map\n",
    "\n",
    "Okee, een kaart met interactiviteit. Vond de Iphyton docs eigenlijk fijner.\n",
    "\n",
    "[interactieve plots] https://towardsdatascience.com/interactive-controls-for-jupyter-notebooks-f5c94829aee6  \n",
    "[iphython widget docs] https://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html\n",
    "\n",
    "### Food change maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:36.599487Z",
     "start_time": "2019-06-19T09:58:14.864Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def map_graph(commodity=selectie, year=(2007, 2019, 1)):\n",
    "    # Plot the mean price, of all commodities on map, of all years.\n",
    "    series = select_commodity(commodity, year)\n",
    "    map_data = [go.Choropleth(\n",
    "        locations = series.index,\n",
    "        locationmode = \"country names\",\n",
    "        z = series.values,\n",
    "    )]\n",
    "\n",
    "    fig = go.Figure(data = map_data)\n",
    "    iplot(fig)\n",
    "    \n",
    "interact(map_graph, commodity=selectie, year=(1996, 2019, 1))\n",
    "interact(map_graph, commodity=selectie, year=(1996, 2019, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controle\n",
    "\n",
    "Om te controleren of de dataset correct is moeten we natuurlijk even een test draaien. Ik heb globale voedselprijzen even als benchmark genomen. Daar ligt waarschijnlijk een sterke correlatie, zeker voor gebieden die niet direct in conflict zijn.\n",
    "\n",
    "[imf commodity prices data] https://www.imf.org/en/Research/commodity-prices  \n",
    "[interessante analyse voedsel] https://ourworldindata.org/food-prices  \n",
    "[interessante statistische analyse van commodities] https://www.imf.org/~/media/Files/Research/CommodityPrices/WEOSpecialFeature/SFApril2019.ashx  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:36.607071Z",
     "start_time": "2019-06-19T09:58:15.516Z"
    }
   },
   "outputs": [],
   "source": [
    "# selecteer rijst en bereken het gemiddelde\n",
    "commodity_imf_df = pd.read_csv(\"./commodity_imf_proper.csv\", dtype=float, decimal=\",\")\n",
    "commodity_imf_df = commodity_imf_df.set_index('Year')\n",
    "\n",
    "def normalize_series(series):\n",
    "    # bootstrap a new normalizer   \n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    # reshape the series to array so that the normalizer accepts it\n",
    "    to_normalize = series.values.reshape(-1, 1)\n",
    "    \n",
    "    # do the actual normalisation     \n",
    "    x_scaled = min_max_scaler.fit_transform(to_normalize)\n",
    "\n",
    "    # undo some weird numpy nesting of arrays    \n",
    "    x_scaled = np.concatenate(x_scaled).ravel()\n",
    "    \n",
    "    # trow the series     \n",
    "    return pd.Series(x_scaled, index = series.index)\n",
    "\n",
    "def line_graph(food):\n",
    "    # create an average of all countries    \n",
    "    test = grouped_commodity_diff_df.xs(food, level=1, drop_level=False).mean()\n",
    "    \n",
    "    # use the IMF data to compute a nomalized and diffed line too    \n",
    "    control = normalize_series(commodity_imf_df[food]).diff()\n",
    "    \n",
    "    test_trace = go.Scatter(\n",
    "        name = \"WFP\",\n",
    "        x = test.index,\n",
    "        y = test.values\n",
    "    )\n",
    "    \n",
    "    control_trace = go.Scatter(\n",
    "        name = \"IMF\",\n",
    "        x = control.index[-25:],\n",
    "        y = control.values[-25:]\n",
    "    )\n",
    "    \n",
    "    iplot([test_trace, control_trace], filename='basic-line')\n",
    "\n",
    "interact(line_graph, food=[\"Rice\", \"Wheat\", \"Sugar\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultaat\n",
    "\n",
    "Er lijkt wel iets van een correlatie te zijn, maar er zitten ook rare verschillen tussen. Metname de pieken zijn veel hoger. Maar duidelijk is dat 2008 een grote impact heeft gehad. Ik denk dat we nog even goed moeten kijken naar hoe we normaliseren. Het is best mogelijk om hiermee te spelen lijkt het, maar wat verantwoord is twijfel ik aan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klimaat\n",
    "\n",
    "Nu eens kijken of het samenhangt met klimaat. Ik heb het gevoel dat hier enige correlatie vinden hier moeilijk gaat worden.\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:36.614256Z",
     "start_time": "2019-06-19T09:58:16.502Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "climate_df = pd.read_csv(\"./climate_data/GlobalLandTemperaturesByCountry.csv\", low_memory=False)\n",
    "display(climate_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type and normalize\n",
    "\n",
    "Here we go again.\n",
    "\n",
    "1. Type the datetime\n",
    "2. Normalize\n",
    "3. Create year averages\n",
    "4. Diff those averages to have something comparable\n",
    "\n",
    "This is just a tad different data though. It's cumulative data, its not the same as money. And the effects are much longer term. Doesn't make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:36.621137Z",
     "start_time": "2019-06-19T09:58:17.076Z"
    }
   },
   "outputs": [],
   "source": [
    "# type properly\n",
    "climate_df_typed = climate_df.copy()\n",
    "climate_df_typed['dt'] = climate_df_typed['dt'].astype('datetime64[ns]')\n",
    "\n",
    "# apply the normalize function (with a partial for the key)\n",
    "climate_norm_df = climate_df_typed.groupby(by=[\"Country\"]).apply(partial(normalize_group, \"AverageTemperature\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform and select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:36.627795Z",
     "start_time": "2019-06-19T09:58:17.688Z"
    }
   },
   "outputs": [],
   "source": [
    "# calulate the mean for the year\n",
    "climate_mean_df = climate_norm_df.groupby(by=[\"Country\", climate_norm_df[\"dt\"].dt.year]).mean()\n",
    "climate_mean_df.reset_index(inplace=True)\n",
    "\n",
    "# quick function with assignment\n",
    "def diff_temp(group_df):\n",
    "    group_df[\"AverageTemperature_diff\"] = group_df[\"AverageTemperature_norm\"].diff()\n",
    "    return group_df\n",
    "\n",
    "# apply the difference function\n",
    "climate_tran_df = climate_mean_df.groupby(by=[\"Country\"]).apply(diff_temp).set_index([\"Country\", \"dt\"])\n",
    "\n",
    "# quick selection function\n",
    "def select_year(year):\n",
    "    return climate_tran_df.xs(year, level=1, drop_level=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map: Tempratuur verschil met vorig jaar\n",
    "\n",
    "Spreekt voor zich, maar of het interessant is is de tweede vraag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:36.634740Z",
     "start_time": "2019-06-19T09:58:18.351Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_climate(year):\n",
    "    year_data = select_year(year)\n",
    "    map_data = go.Choropleth(locations=year_data.index.get_level_values(0),\n",
    "                             locationmode=\"country names\",\n",
    "                             z=year_data[\"AverageTemperature_diff\"].values)\n",
    "    \n",
    "    fig = go.Figure(data=[map_data])\n",
    "\n",
    "    iplot(fig)\n",
    "\n",
    "interact(map_climate, year=(1996, 2013, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparklines Climate\n",
    "\n",
    "Misschien is een totaalbeeld beter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:36.642677Z",
     "start_time": "2019-06-19T09:58:18.917Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/1962_2006_walmart_store_openings.csv')\n",
    "display(df.head())\n",
    "\n",
    "data = []\n",
    "layout = dict(\n",
    "    title = 'New Walmart Stores per year 1962-2006<br>\\\n",
    "Source: <a href=\"http://www.econ.umn.edu/~holmes/data/WalMart/index.html\">\\\n",
    "University of Minnesota</a>',\n",
    "    # showlegend = False,\n",
    "    autosize = False,\n",
    "    width = 1000,\n",
    "    height = 900,\n",
    "    hovermode = False,\n",
    "    legend = dict(\n",
    "        x=0.7,\n",
    "        y=-0.1,\n",
    "        bgcolor=\"rgba(255, 255, 255, 0)\",\n",
    "        font = dict( size=11 ),\n",
    "    )\n",
    ")\n",
    "years = df['YEAR'].unique()\n",
    "\n",
    "for i in range(len(years)):\n",
    "    geo_key = 'geo'+str(i+1) if i != 0 else 'geo'\n",
    "    lons = list(df[ df['YEAR'] == years[i] ]['LON'])\n",
    "    lats = list(df[ df['YEAR'] == years[i] ]['LAT'])\n",
    "    # Walmart store data\n",
    "    data.append(\n",
    "        dict(\n",
    "            type = 'scattergeo',\n",
    "            showlegend=False,\n",
    "            lon = lons,\n",
    "            lat = lats,\n",
    "            geo = geo_key,\n",
    "            name = str(years[i]),\n",
    "            marker = dict(\n",
    "                color = \"rgb(0, 0, 255)\",\n",
    "                opacity = 0.5\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # Year markers\n",
    "    data.append(\n",
    "        dict(\n",
    "            type = 'scattergeo',\n",
    "            showlegend = False,\n",
    "            lon = [-78],\n",
    "            lat = [47],\n",
    "            geo = geo_key,\n",
    "            text = [years[i]],\n",
    "            mode = 'text',\n",
    "        )\n",
    "    )\n",
    "    layout[geo_key] = dict(\n",
    "        scope = 'usa',\n",
    "        showland = True,\n",
    "        landcolor = 'rgb(229, 229, 229)',\n",
    "        showcountries = False,\n",
    "        domain = dict( x = [], y = [] ),\n",
    "        subunitcolor = \"rgb(255, 255, 255)\",\n",
    "    )\n",
    "\n",
    "\n",
    "def draw_sparkline( domain, lataxis, lonaxis ):\n",
    "    ''' Returns a sparkline layout object for geo coordinates  '''\n",
    "    return dict(\n",
    "        showland = False,\n",
    "        showframe = False,\n",
    "        showcountries = False,\n",
    "        showcoastlines = False,\n",
    "        domain = domain,\n",
    "        lataxis = lataxis,\n",
    "        lonaxis = lonaxis,\n",
    "        bgcolor = 'rgba(255,200,200,0.0)'\n",
    "    )\n",
    "\n",
    "# Stores per year sparkline\n",
    "layout['geo44'] = draw_sparkline({'x':[0.6,0.8], 'y':[0,0.15]}, \\\n",
    "                                 {'range':[-5.0, 30.0]}, {'range':[0.0, 40.0]} )\n",
    "data.append(\n",
    "    dict(\n",
    "        type = 'scattergeo',\n",
    "        mode = 'lines',\n",
    "        lat = list(df.groupby(by=['YEAR']).count()['storenum']/1e1),\n",
    "        lon = list(range(len(df.groupby(by=['YEAR']).count()['storenum']/1e1))),\n",
    "        line = dict( color = \"rgb(0, 0, 255)\" ),\n",
    "        name = \"New stores per year<br>Peak of 178 stores per year in 1990\",\n",
    "        geo = 'geo44',\n",
    "    )\n",
    ")\n",
    "\n",
    "# Cumulative sum sparkline\n",
    "layout['geo45'] = draw_sparkline({'x':[0.8,1], 'y':[0,0.15]}, \\\n",
    "                                 {'range':[-5.0, 50.0]}, {'range':[0.0, 50.0]} )\n",
    "data.append(\n",
    "    dict(\n",
    "        type = 'scattergeo',\n",
    "        mode = 'lines',\n",
    "        lat = list(df.groupby(by=['YEAR']).count().cumsum()['storenum']/1e2),\n",
    "        lon = list(range(len(df.groupby(by=['YEAR']).count()['storenum']/1e1))),\n",
    "        line = dict( color = \"rgb(214, 39, 40)\" ),\n",
    "        name =\"Cumulative sum<br>3176 stores total in 2006\",\n",
    "        geo = 'geo45',\n",
    "    )\n",
    ")\n",
    "\n",
    "z = 0\n",
    "COLS = 5\n",
    "ROWS = 9\n",
    "for y in reversed(range(ROWS)):\n",
    "    for x in range(COLS):\n",
    "        geo_key = 'geo'+str(z+1) if z != 0 else 'geo'\n",
    "        layout[geo_key]['domain']['x'] = [float(x)/float(COLS), float(x+1)/float(COLS)]\n",
    "        layout[geo_key]['domain']['y'] = [float(y)/float(ROWS), float(y+1)/float(ROWS)]\n",
    "        z=z+1\n",
    "        if z > 42:\n",
    "            break\n",
    "\n",
    "\n",
    "layout = {**layout, \"height\":900, \"width\":1000 }\n",
    "fig = { 'data':data, 'layout': layout}\n",
    "iplot( fig, filename='US Walmart growth' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Events\n",
    "\n",
    "Okee, wat moet ik hiervoor doen. Querys schrijven naar Google Big Query. Cool, eens kijken hoe dat werkt.\n",
    "\n",
    "[GDELT database] https://www.gdeltproject.org/  \n",
    "[forecasting op voedseldata] https://dataviz.vam.wfp.org/economic_explorer/price-forecasts-alerts  \n",
    "[redelijke uitleg GDELT] http://data.gdeltproject.org/documentation/GDELT-Event_Codebook-V2.0.pdf  \n",
    "[Uitleg gebruikte codes] https://www.gdeltproject.org/data/documentation/CAMEO.Manual.1.1b3.pdf  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:19:24.837795Z",
     "start_time": "2019-06-15T09:19:24.827976Z"
    }
   },
   "source": [
    "## Download data\n",
    "\n",
    "Er is een Python client voor bigquery. Het is best simpel eigenlijk.\n",
    "\n",
    "1. De clientlib installeren\n",
    "2. Credentials file exporten in je shell (ik heb het aan mijn ~/.bash_profile toegevoegd en die gesourced, werkt perfect - MAC/Linux-only helaas)\n",
    "2. Draai de sample query\n",
    "3. Doe dingen met het dataframe\n",
    "\n",
    "[setup credentials] https://cloud.google.com/bigquery/docs/reference/libraries#client-libraries-install-python  \n",
    "[database description] https://bigquery.cloud.google.com/table/gdelt-bq:gdeltv2.events?pli=1  \n",
    "[API reference] https://googleapis.github.io/google-cloud-python/latest/bigquery/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:36.651626Z",
     "start_time": "2019-06-19T09:58:19.819Z"
    }
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "# write a good query to the right table (lookup the database stuffz)\n",
    "query = (\n",
    "    \"SELECT V2Themes FROM `gdelt-bq.gdeltv2.gkg` WHERE DATE>20150302000000 and DATE < 20150304000000 and V2Persons like '%Netanyahu%' LIMIT 10;\"\n",
    ")\n",
    "\n",
    "# create the query\n",
    "query_job = client.query(\n",
    "    query,\n",
    "    location=\"US\",\n",
    ")\n",
    "\n",
    "# run the query and turn the result to a dataframe\n",
    "result = query_job.result().to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query\n",
    "\n",
    "Wat moet het kunnen?\n",
    "\n",
    "Het moet sentiment en count per land per jaar of maand geven.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T09:58:36.658665Z",
     "start_time": "2019-06-19T09:58:20.427Z"
    }
   },
   "outputs": [],
   "source": [
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "\n",
    "## Food\n",
    "Dit is onze hoofddataset, dus veel detailvisualisaties.\n",
    "\n",
    "0. [ x ] Drop messy date columns\n",
    "  \n",
    "1. [ x ] Scatter transform van price naar price_norm  \n",
    "  \n",
    "2. [ x ] Matrix   \n",
    "    2.1. [ x ] Matrix transform interactief/y-as van goods naar country    \n",
    "    2.2. [ x ] Matrix transform z-as van count naar price en price_norm  \n",
    "  \n",
    "3. [  ] Gridplot van een commodity per land om een diachroon perspectief te krijgen  \n",
    "3.1. [  ] mp_price/jaar  \n",
    "3.2. [  ] mp_price_norm/jaar  \n",
    "  \n",
    "4. [  ] Totaalplot  \n",
    "    4.1. [  ] IMF Wereldcommodities aanvullen met scatterplot  \n",
    "    4.2. [  ] Correlatiematrix binnen een commodity in een land maken  \n",
    "    4.3. [  ] Slechte correlaties droppen  \n",
    "    4.4. [  ] Correlatiematrix tussen dezelfde commodity tussen landen  \n",
    "    4.5. [  ] Slechte correlaties droppen   \n",
    "    4.6. [  ] Correlatie met wereldcommodities maken  \n",
    "\n",
    "5. [  ] Correlatie plots\n",
    "    5.1. [  ] Correlation scatter grid\n",
    "    5.2. [  ] Correlation diagram\n",
    "\n",
    "5. [  ] Detail in alle grafieken naar maanden verhogen  \n",
    "5.1. [  ] Matrix  \n",
    "5.2. [  ] Lijn  \n",
    "   \n",
    "6. [  ] Maps naar provincie of stadsniveau  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klimaat\n",
    "\n",
    "### EDA\n",
    "1. Dit is het zwakke van klimaat, ik heb eigenlijk nog geen goed overzicht van distributes en ander inzicht in de kwaliteit van die set. \n",
    "2. Iets van diachronaal perspectief op deze set, om uberhaubt te checken dat het geen nagenoeg rechte lijn van 1990-2013 is. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events\n",
    "\n",
    "### Opzetten\n",
    "\n",
    "#### Gemiddelden checken \n",
    "1. Goede query opstellen. Dit wordt eigenlijk de grote crux. In principe moeten we BigQuery al het werk laten doen hier. Het resultaat dat we willen hebben is niet zo heel erg gedetailleerd. \n",
    "2. Transformeren naar een vergelijkbaar dataframe. \n",
    "3. Plotten in lijn en kaart\n",
    "\n",
    "#### Individuele events checken\n",
    "4. Eventdetectie in de food dataset\n",
    "5. Event en food events tegen elkaar afzetten\n",
    "\n",
    "### EDA\n",
    "6. Alles\n",
    "\n",
    "### Kwaliteit\n",
    "7. Wat de data precies beschrijven en wat de bronnen zijn twijfel ik ook nog aan. Het is regelrecht gigantisch en het is een academisch project. Maar dit is wel een extreem complexe set, met veel artikelen over hoe het gecodeerd is. (denk Goldstein sentiment en counts.. van wat precies?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlaties\n",
    "1. Proberen goederen te clusteren tot een enkele lijn per land / wereld\n",
    "2. Visuele EDA op de correlaties\n",
    "3. Correlaties van die lijn inferentieel onderzoeken en tot een coefficient omzetten voor uiteindelijke conclusie.\n",
    "    - Nadenken over welke assumpties daar ook al weer voor golden en welke tests dus aan voldaan moet zijn.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
